{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"dask_horizontal.svg\" style=\"height:200px\" />\n",
    "\n",
    "## *Because not all problems are dataframes...*\n",
    "\n",
    "Fuente: https://examples.dask.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_session import DaskSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Por qué Dask?\n",
    "\n",
    "### Los analistas suelen utilizar herramientas como Pandas, Scikit-Learn, Numpy y el resto del ecosistema de Python para analizar datos en su computadora personal. Les gustan estas herramientas porque son eficientes, intuitivas y de gran confianza. Sin embargo, cuando eligen aplicar sus análisis a conjuntos de datos más grandes, descubren que estas herramientas no fueron diseñadas para escalar más allá de una sola máquina. Y así, el analista reescribe su cálculo utilizando una herramienta más escalable, a menudo en otro idioma. Este proceso de reescritura ralentiza el descubrimiento y causa frustración.\n",
    "\n",
    "### Dask proporciona formas de escalar los flujos de trabajo de Pandas, Scikit-Learn y Numpy de forma más nativa, con una reescritura mínima. Se integra bien con estas herramientas, por lo que copia la mayor parte de su API y utiliza sus estructuras de datos internamente. Además, Dask se ha desarrollado conjuntamente con estas bibliotecas para garantizar que evolucionen de manera constante, minimizando la fricción al pasar de una computadora portátil local a una estación de trabajo de varios núcleos y luego a un clúster distribuido. Los analistas familiarizados con Pandas / Scikit-Learn / Numpy se familiarizarán inmediatamente con sus equivalentes de Dask, y gran parte de su intuición se trasladará a un contexto escalable.\n",
    "\n",
    "Fuente: https://docs.dask.org/en/latest/why.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_session = DaskSession()\n",
    "init_session.client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask escala a clústeres\n",
    "### Como los conjuntos de datos y los cálculos se escalan más rápido que las CPU y la RAM, necesitamos encontrar formas de escalar nuestros cálculos en varias máquinas. Esto introduce muchas preocupaciones nuevas:\n",
    "\n",
    "- ¿Cómo hacer que las computadoras se comuniquen entre sí a través de la red?\n",
    "- ¿Cómo y cuándo mover datos entre máquinas?\n",
    "- ¿Cómo recuperarse de las fallas de la máquina?\n",
    "- ¿Cómo implementar en un clúster interno?\n",
    "- ¿Cómo implementar en la nube?\n",
    "- ¿Cómo implementar en una supercomputadora HPC?\n",
    "- ¿Cómo proporcionar una API a este sistema que los usuarios encuentren intuitiva?\n",
    "- ...\n",
    "\n",
    "\n",
    "### Dask resuelve los problemas anteriores. Descubre cómo dividir grandes cálculos y enrutar partes de ellos de manera eficiente en hardware distribuido. Dask se ejecuta habitualmente en clústeres de miles de máquinas para procesar cientos de terabytes de datos de manera eficiente dentro de entornos seguros.\n",
    "\n",
    "### Dask tiene utilidades y documentación sobre cómo implementar internamente, en la nube o en supercomputadoras HPC. Admite cifrado y autenticación mediante certificados TLS / SSL. Es resistente y puede manejar el fallo de los nodos de trabajo con elegancia y es elástico, por lo que puede aprovechar los nuevos nodos agregados sobre la marcha. Dask incluye varias API de usuario que son utilizadas y perfeccionadas por miles de investigadores de todo el mundo que trabajan en diferentes dominios.\n",
    "\n",
    "Fuente: https://docs.dask.org/en/latest/why.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'set_your_data_path'\n",
    "\n",
    "dd.read_parquet(data_path).to_dask_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.read_parquet(data_path).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.read_parquet(data_path).to_dask_array().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask admite aplicaciones complejas\n",
    "### Algunos cálculos paralelos son simples y simplemente aplican la misma rutina en muchas entradas sin ningún tipo de coordinación. Son fáciles de paralelizar con cualquier sistema.\n",
    "\n",
    "### Se pueden expresar cálculos algo más complejos con el patrón map-shuffle-reduce popularizado por Hadoop y Spark. Esto suele ser suficiente para realizar la mayoría de las tareas de limpieza de datos, consultas de estilo de base de datos y algunos algoritmos ligeros de aprendizaje automático.\n",
    "\n",
    "### Sin embargo, existen cálculos paralelos más complejos que no encajan en estos paradigmas, por lo que son difíciles de realizar con las tecnologías tradicionales de big data. Estos incluyen algoritmos más avanzados para estadísticas o aprendizaje automático, series de tiempo u operaciones locales, o paralelismo personalizado que a menudo se encuentra dentro de los sistemas de las grandes empresas.\n",
    "\n",
    "### Hoy en día, muchas empresas e instituciones tienen problemas que son claramente paralelizables, pero no claramente transformables en un gran cálculo de DataFrame. Hoy en día, estas empresas tienden a resolver sus problemas escribiendo código personalizado con sistemas de bajo nivel como MPI, ZeroMQ o sockets y sistemas de cola complejos, o introduciendo su problema en una tecnología estándar de big data como MapReduce o Spark, y esperando el mejor.\n",
    "\n",
    "### Dask ayuda a resolver estas situaciones al exponer API de bajo nivel a su programador de tareas interno, que es capaz de ejecutar cálculos muy avanzados. Esto brinda a los ingenieros dentro de la institución la capacidad de construir su propio sistema de computación en paralelo utilizando el mismo motor que impulsa las matrices, los DataFrames y los algoritmos de aprendizaje automático de Dask, pero ahora con la propia lógica personalizada de la institución. Esto permite a los ingenieros mantener la lógica empresarial compleja internamente mientras siguen confiando en Dask para manejar la comunicación de red, el equilibrio de carga, la resistencia, los diagnósticos, etc.\n",
    "\n",
    "Fuente: https://docs.dask.org/en/latest/why.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc(x):\n",
    "    time.sleep(random.random())\n",
    "    return x + 1\n",
    "\n",
    "def dec(x):\n",
    "    time.sleep(random.random())\n",
    "    return x - 1\n",
    "\n",
    "def add(x, y):\n",
    "    time.sleep(random.random())\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x = inc(1)\n",
    "y = dec(2)\n",
    "z = add(x, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora vamos a usar el decorador @dask para aplicar el método delayed y generar un comportamiento lazy. Dask.delayed es una forma simple y poderosa de paralelizar el código existente. Permite a los usuarios retrasar las llamadas a funciones en un gráfico de tareas con dependencias. Dask.delayed no proporciona ningún algoritmo paralelo elegante como Dask.dataframe, pero le da al usuario un control completo sobre lo que quiere construir.\n",
    "\n",
    "### Los sistemas como Dask.dataframe se crean con Dask.delayed. Si tiene un problema que es paralelizable, pero que no es tan simple como una gran matriz o un gran marco de datos, entonces dask.delayed puede ser la opción correcta para usted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def inc(x):\n",
    "    time.sleep(random.random())\n",
    "    return x + 1\n",
    "\n",
    "@dask.delayed\n",
    "def dec(x):\n",
    "    time.sleep(random.random())\n",
    "    return x - 1\n",
    "\n",
    "@dask.delayed\n",
    "def add(x, y):\n",
    "    time.sleep(random.random())\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x = inc(1)\n",
    "y = dec(2)\n",
    "z = add(x, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.visualize(rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "zs = []\n",
    "\n",
    "for i in range(128):\n",
    "    x = inc(i)\n",
    "    y = dec(x)\n",
    "    z = add(x, y)\n",
    "    zs.append(z)\n",
    "\n",
    "zs = dask.persist(*zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sumamos los vecinos de cada nivel del arbol\n",
    "\n",
    "#         5\n",
    "#     3       3\n",
    "#   2   4   4   4\n",
    "# 1   1   4   7   3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = zs\n",
    "\n",
    "while len(L) > 1:\n",
    "    new_L = []\n",
    "    for i in range(0, len(L), 2):\n",
    "        lazy = add(L[i], L[i + 1])\n",
    "        new_L.append(lazy)\n",
    "    L = new_L\n",
    "    \n",
    "dask.compute(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ophelia",
   "language": "python",
   "name": "ophelia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
